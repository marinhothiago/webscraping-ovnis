# -*- coding: utf-8 -*-
"""webscraping_ovnis.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1W-st7J7BvX0sDolO4krHV-06DIuoGl6Z
"""

import requests
import pandas as pd
from bs4 import BeautifulSoup

#inicializa variaveis de meses e anos
anos = []
meses = ['01','02','03','04','05','06','07','08','09','10','11','12']

#gerando a lista em colunas
data_hora=[]
cidade=[]
estado=[]
shape=[]
duracao=[]
descricao=[]
postado=[]

#determina o intervalo de anos a serem pesquisados (1997 - 2017)
for i in range(1997,2018):
  converte = str(i)
  anos.append(converte)

for ano in anos:
  for mes in meses:
    #Concatena URL de acordo com os meses e anos requisitados
    url = "http://www.nuforc.org/webreports/ndxe"+ano+""+mes+".html"

    #Atribui url a um request para acessar a pagina HTML e seus componentes
    req = requests.get(url)
    soup = BeautifulSoup(req.content, 'html.parser')

    #Coloca os conteúdos da tabela na variavel table
    table = soup.find('table')

    for row in table.findAll("tr"): #para tudo que estiver em <tr>
      dado = row.findAll('td') #variável para encontrar <td>
      if len(dado)==7: #número de colunas
        data_hora.append(dado[0].find(text=True)) #iterando sobre cada linha
        cidade.append(dado[1].find(text=True))
        estado.append(dado[2].find(text=True))
        shape.append(dado[3].find(text=True))
        duracao.append(dado[4].find(text=True))
        descricao.append(dado[5].find(text=True))
        postado.append(dado[6].find(text=True))

#declara dataframe
df = pd.DataFrame()

#atribui colunas as variaveis criadas
df['Date / Time']=data_hora
df['City']=cidade
df['State']=estado
df['Shape']=shape
df['Duration']=duracao
df['Summary']=descricao
df['Posted']=postado

#gera arquivo .csv
df.to_csv("ovnis.csv")

#mostra dataframe
df